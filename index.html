<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta content="IE=5.0000" http-equiv="X-UA-Compatible">
    <meta name="description" content="Rongyao Fang's home page">
    <title>Rongyao Fang's Homepage</title>
    <meta name="GENERATOR" content="MSHTML 11.00.10570.1001">
    <style type="text/css">
        body {
            margin: 30px auto;
            padding: 10px 50px 30px;
            text-align: left;
            color: rgb(0, 0, 0);
            font-family: Georgia, serif;
            max-width: 960px;
            background-color: rgb(255, 255, 255);
        }
        html {
            background-color: rgb(238, 238, 238);
        }
        #layout-content {
            background: white;
            border: currentColor;
            text-align: left;
            padding-top: 0em;
            padding-right: 1em;
            padding-left: 1em;
            vertical-align: top;
        }
        a {
            color: rgb(34, 75, 141);
            text-decoration: none;
        }
        a:hover {
            border-bottom: 1px dotted gray;
        }
        div#toptitle {
            padding-bottom: 0.2em;
            margin-bottom: 1.5em;
        }
        div#toptitle h1 {
            padding-top: 0px;
            padding-bottom: 0.1em;
            margin-top: 0.5em;
            margin-bottom: 0em;
            border-bottom: none;
        }
        h1, h2, h3 {
            color: rgb(82, 123, 189);
            line-height: 1;
            padding-top: 0.5em;
            padding-bottom: 0.2em;
            margin-top: 0.7em;
            margin-bottom: 0.5em;
            border-bottom: 1px solid rgb(170, 170, 170);
        }
        h1 {
            font-size: 165%;
        }
        h2 {
            padding-top: 0.8em;
            font-size: 125%;
        }
        h3 {
            font-size: 110%;
            border-bottom: none;
        }
        p {
            padding: 0px;
            line-height: 1.3;
            margin-top: 0em;
            margin-bottom: 0.8em;
        }
        ul {
            padding-top: 0px;
            margin-top: 0.2em;
            margin-bottom: 0.8em;
            list-style-type: square;
            list-style-position: outside;
        }
        li {
            margin-top: 0.9em;
        }
        table {
            padding: 5px;
            border-collapse: collapse; /* Better table rendering */
        }
        td {
            padding: 5px; /* Add some padding to table cells */
        }
        img {
            border: none;
        }
        strong {
            font-weight: bold;
        }
        b {
            font-weight: bold;
        }
    </style>
</head>

<body>
    <div id="layout-content" style="margin-top: 25px;">
        <table>
            <tbody>
                <tr>
                    <!-- 照片放在左边 -->
                    <td width="280">
                        <div>
                            <!-- 照片链接已更新 -->
                            <img width="240" src="images/avatar.jpg" alt="Rongyao Fang">
                        </div>
                    </td>
                    <td style="vertical-align: top;">
                        <div id="toptitle">
                            <h1>Rongyao Fang (方荣耀)</h1>
                        </div>
                        <h3>Ph.D. Candidate</h3>
                        <p>
                            <a href="https://mmlab.ie.cuhk.edu.hk/" target="_blank">Multimedia Laboratory (MMLab)</a>
                            <br>Department of Electronic Engineering,
                            <br>The Chinese University of Hong Kong (CUHK),
                            <br>Hong Kong, China
                            <br>
                            <br> Email:
                            <a href="mailto:rongyaofang@gmail.com">rongyaofang@gmail.com</a>
                            <br>
                            <br> 
                            [<a href="https://scholar.google.com/citations?user=FtH3CW4AAAAJ&hl=en" target="_blank">Google Scholar</a>]
                            &nbsp;&nbsp;
                            [<a href="https://github.com/rongyaofang" target="_blank">GitHub</a>]
                            &nbsp;&nbsp;
                            [<a href="images/CV-Rongyao Fang.pdf" target="_blank">CV</a>]
                        </p>
                    </td>
                </tr>
            </tbody>
        </table>

        <h2>Biography</h2>
        <p>
            I am a Ph.D. candidate at the <a href="https://mmlab.ie.cuhk.edu.hk/" target="_blank">Multimedia Laboratory (MMLab)</a> of The Chinese University of Hong Kong (CUHK), fortunate to be supervised by <a href="https://www.ee.cuhk.edu.hk/~hsli/" target="_blank">Prof. Hongsheng Li</a>. I also work closely with <a href="https://xh-liu.github.io/" target="_blank">Prof. Xihui Liu</a>. I anticipate completing my doctorate in 2025.
            <br><br>
            My research is driven by a passion for <strong>Artificial General Intelligence (AGI)</strong> with a focus on visual understanding and generation. I am dedicated to developing integrated systems capable of perceiving, understanding, and generating visual content by leveraging advanced techniques with Multimodal Large Language Models.
            <br><br>
            Previously, I was a visiting scholar at MIT CSAIL, advised by <a href="https://www.csail.mit.edu/person/dina-katabi" target="_blank">Prof. Dina Katabi</a>. I obtained my B.Eng. degree from Shanghai Jiao Tong University, where I was ranked <strong>1st/157</strong> and advised by <a href="https://scholar.google.com/citations?user=ThU-QkYAAAAJ&hl=en" target="_blank">Prof. Bingbing Ni</a>.
        </p>

        <h2>Education</h2>
        <ul>
            <li>
                [2021 - 2025 (Exp.)] Ph.D. candidate at MMLab, The Chinese University of Hong Kong.
            </li>
            <li>
                [2016 - 2020] B.Eng. in Information Engineering, Shanghai Jiao Tong University (Ranking: <strong>1st/157</strong>).
            </li>
            <li>
                [2019 - 2020] Visiting Scholar at CSAIL, Massachusetts Institute of Technology.
            </li>
        </ul>
        
        <h2>Publications</h2>
        <p>(* indicates equal contribution)</p>
        
        <ul>
            <li>
                <div style="margin-top: 15px;"><b>GoT-R1: Unleashing Reasoning Capability of MLLM for Visual Generation with Reinforcement Learning</b></div>
                <div style="margin-top: 5px;"><a style="color: #777;">C Duan*, <strong style="color: #444444;">Rongyao Fang*</strong>, Y Wang*, K Wang, L Huang, X Zeng, H Li, X Liu</a></div>
                <div style="margin-top: 5px;"><i>arXiv preprint, 2025</i></div>
            </li>
            <li>
                <div style="margin-top: 15px;"><b>GoT: Unleashing Reasoning Capability of Multimodal Large Language Model for Visual Generation and Editing</b></div>
                <div style="margin-top: 5px;"><a style="color: #777;"><strong style="color: #444444;">Rongyao Fang</strong>, C Duan, K Wang, L Huang, H Li, S Yan, H Tian, X Zeng, R Zhao, J Dai, X Liu, H Li</a></div>
                <div style="margin-top: 5px;"><i>arXiv preprint, 2025</i></div>
            </li>
			<li>
                <div style="margin-top: 15px;"><b>CrossLMM: Decoupling Long Video Sequences from LMMs via Dual Cross-Attention Mechanisms</b></div>
                <div style="margin-top: 5px;"><a style="color: #777;">S Yan, J Han, J Tsai, H Xue, <strong style="color: #444444;">Rongyao Fang</strong>, L Hong, Z Guo, R Zhang</a></div>
                <div style="margin-top: 5px;"><i>arXiv preprint, 2025</i></div>
            </li>
            <li>
                <div style="margin-top: 15px;"><b>SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving</b></div>
                <div style="margin-top: 5px;"><a style="color: #777;">X Chen, L Huang, T Ma, <strong style="color: #444444;">Rongyao Fang</strong>, S Shi, H Li</a></div>
                <div style="margin-top: 5px;"><i>Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2025</i></div>
            </li>
            <li>
                <div style="margin-top: 15px;"><b>StreamChat: Chatting with Streaming Video</b></div>
                <div style="margin-top: 5px;"><a style="color: #777;">J Liu, Z Yu, S Lan, S Wang, <strong style="color: #444444;">Rongyao Fang</strong>, J Kautz, H Li, JM Alvare</a></div>
                <div style="margin-top: 5px;"><i>arXiv preprint, 2024</i></div>
            </li>
            <li>
                <div style="margin-top: 15px;"><b>Puma: Empowering Unified MLLM with Multi-Granular Visual Generation</b></div>
                <div style="margin-top: 5px;"><a style="color: #777;"><strong style="color: #444444;">Rongyao Fang</strong>, C Duan, K Wang, H Li, H Tian, X Zeng, R Zhao, J Dai, H Li, X Liu</a></div>
                <div style="margin-top: 5px;"><i>arXiv preprint, 2024</i></div>
            </li>
            <li>
                <div style="margin-top: 15px;"><b>Mimic Before Reconstruct: Enhancing Masked Autoencoders with Feature Mimicking</b></div>
                <div style="margin-top: 5px;"><a style="color: #777;">P Gao, Z Lin, R Zhang, <strong style="color: #444444;">Rongyao Fang</strong>, H Li, H Li, Y Qiao</a></div>
                <div style="margin-top: 5px;"><i>International Journal of Computer Vision (<b>IJCV</b>), 2024</i></div>
            </li>
            <li>
                <div style="margin-top: 15px;"><b>FeatAug-DETR: Enriching One-to-Many Matching for DETRs with Feature Augmentation</b></div>
                <div style="margin-top: 5px;"><a style="color: #777;"><strong style="color: #444444;">Rongyao Fang</strong>, P Gao, A Zhou, Y Cai, S Liu, J Dai, H Li</a></div>
                <div style="margin-top: 5px;"><i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2024</i></div>
            </li>
            <li>
                <div style="margin-top: 15px;"><b>FouriScale: A Frequency Perspective on Training-Free High-Resolution Image Synthesis</b></div>
                <div style="margin-top: 5px;"><a style="color: #777;">L Huang*, <strong style="color: #444444;">Rongyao Fang*</strong>, A Zhang, G Song, S Liu, Y Liu, H Li</a></div>
                <div style="margin-top: 5px;"><i>European Conference on Computer Vision (<b>ECCV</b>), 2024</i></div>
            </li>
            <li>
                <div style="margin-top: 15px;"><b>Clip-Adapter: Better Vision-Language Models with Feature Adapters</b></div>
                <div style="margin-top: 5px;"><a style="color: #777;">P Gao, S Geng, R Zhang, T Ma, <strong style="color: #444444;">Rongyao Fang</strong>, Y Zhang, H Li, Y Qiao</a></div>
                <div style="margin-top: 5px;"><i>International Journal of Computer Vision (<b>IJCV</b>), 2024</i></div>
            </li>
            <li>
                <div style="margin-top: 15px;"><b>InstructSeq: Unifying Vision Tasks with Instruction-Conditioned Multi-Modal Sequence Generation</b></div>
                <div style="margin-top: 5px;"><a style="color: #777;"><strong style="color: #444444;">Rongyao Fang</strong>, S Yan, Z Huang, J Zhou, H Tian, J Dai, H Li</a></div>
                <div style="margin-top: 5px;"><i>arXiv preprint, 2023</i></div>
            </li>
            <li>
                <div style="margin-top: 15px;"><b>Point-M2AE: Multi-Scale Masked Autoencoders for Hierarchical Point Cloud Pre-Training</b></div>
                <div style="margin-top: 5px;"><a style="color: #777;">R Zhang, Z Guo, P Gao, <strong style="color: #444444;">Rongyao Fang</strong>, B Zhao, D Wang, Y Qiao, H Li</a></div>
                <div style="margin-top: 5px;"><i>Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2022</i></div>
            </li>
            <li>
                <div style="margin-top: 15px;"><b>RBGNet: Ray-Based Grouping for 3D Object Detection</b></div>
                <div style="margin-top: 5px;"><a style="color: #777;">H Wang, S Shi, Z Yang, <strong style="color: #444444;">Rongyao Fang</strong>, Q Qian, H Li, B Schiele, L Wang</a></div>
                <div style="margin-top: 5px;"><i>Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022</i></div>
            </li>
            <li>
                <div style="margin-top: 15px;"><b>Tip-Adapter: Training-Free CLIP-Adapter for Better Vision-Language Modeling</b></div>
                <div style="margin-top: 5px;"><a style="color: #777;">R Zhang*, <strong style="color: #444444;">Rongyao Fang*</strong>, P Gao*, W Zhang, K Li, J Dai, Y Qiao, H Li</a></div>
                <div style="margin-top: 5px;"><i>European Conference on Computer Vision (<b>ECCV</b>), 2022</i></div>
            </li>
            <li>
                <div style="margin-top: 15px;"><b>Learning Longterm Representations for Person Re-Identification Using Radio Signals</b></div>
                <div style="margin-top: 5px;"><a style="color: #777;">L Fan*, T Li*, <strong style="color: #444444;">Rongyao Fang*</strong>, R Hristov, Y Yuan, D Katabi</a></div>
                <div style="margin-top: 5px;"><i>Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2020</i></div>
            </li>
            <li>
                <div style="margin-top: 15px;"><b>Probabilistic Radiomics: Ambiguous Diagnosis with Controllable Shape Analysis</b></div>
                <div style="margin-top: 5px;"><a style="color: #777;">J Yang*, <strong style="color: #444444;">Rongyao Fang*</strong>, B Ni, Y Li, Y Xu, L Li</a></div>
                <div style="margin-top: 5px;"><i>International Conference on Medical Image Computing and Computer-Assisted Intervention (<b>MICCAI</b>), 2019</i></div>
            </li>
            <li>
                <div style="margin-top: 15px;"><b>Adversarial Attack and Defense on Point Sets</b></div>
                <div style="margin-top: 5px;"><a style="color: #777;">J Yang*, Q Zhang*, <strong style="color: #444444;">Rongyao Fang*</strong>, B Ni, J Liu, Q Tian</a></div>
                <div style="margin-top: 5px;"><i>arXiv preprint, 2019</i></div>
            </li>
        </ul>

        <h2>Experience</h2>
        <ul>
            <li>
                [Feb. 2024 - Present] Research Intern, <strong>SenseTime</strong>.
            </li>
            <li>
                [Jun. 2022 - Apr. 2023] Research Intern, <strong>Shanghai AI Laboratory</strong>.
            </li>
        </ul>

        <h2>Selected Awards</h2>
        <ul>
            <li>
                [2021] Hong Kong PhD Fellowship.
            </li>
            <li>
                [2020] Outstanding Graduates of Shanghai (Top <strong>1%</strong>).
            </li>
            <li>
                [2017 & 2018] National Scholarship (Top <strong>1%</strong>).
            </li>
            <li>
                [2017 & 2018] Zhiyuan College Honors Scholarship (Top <strong>5%</strong>).
            </li>
        </ul>
    </div>
    <!-- ClustrMaps 访客地图插件 -->
    <div style="text-align: center; margin-top: 15px; margin-bottom: 15px;">
        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=70&t=n&d=fo2d1M63A9GgJfrICJNySyGcchtKrwm3xME88Jz7c9s&co=ffffff&ct=ffffff&cmo=ffffff&cmn=ffffff'></script>
    </div>
</body>
</html>